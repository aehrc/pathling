"use strict";(globalThis.webpackChunkpathling_site=globalThis.webpackChunkpathling_site||[]).push([[6195],{1470:(e,a,n)=>{n.d(a,{A:()=>S});var r=n(6540),t=n(4164),s=n(7559),i=n(3104),o=n(6347),l=n(205),c=n(7485),u=n(1682),p=n(679);function d(e){return r.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:a}=e;return!!a&&"object"==typeof a&&"value"in a}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:a,children:n}=e;return(0,r.useMemo)(()=>{const e=a??function(e){return d(e).map(({props:{value:e,label:a,attributes:n,default:r}})=>({value:e,label:a,attributes:n,default:r}))}(n);return function(e){const a=(0,u.XI)(e,(e,a)=>e.value===a.value);if(a.length>0)throw new Error(`Docusaurus error: Duplicate values "${a.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[a,n])}function g({value:e,tabValues:a}){return a.some(a=>a.value===e)}function f({queryString:e=!1,groupId:a}){const n=(0,o.W6)(),t=function({queryString:e=!1,groupId:a}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:e,groupId:a});return[(0,c.aZ)(t),(0,r.useCallback)(e=>{if(!t)return;const a=new URLSearchParams(n.location.search);a.set(t,e),n.replace({...n.location,search:a.toString()})},[t,n])]}function b(e){const{defaultValue:a,queryString:n=!1,groupId:t}=e,s=h(e),[i,o]=(0,r.useState)(()=>function({defaultValue:e,tabValues:a}){if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!g({value:e,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${a.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const n=a.find(e=>e.default)??a[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:a,tabValues:s})),[c,u]=f({queryString:n,groupId:t}),[d,b]=function({groupId:e}){const a=function(e){return e?`docusaurus.tab.${e}`:null}(e),[n,t]=(0,p.Dv)(a);return[n,(0,r.useCallback)(e=>{a&&t.set(e)},[a,t])]}({groupId:t}),k=(()=>{const e=c??d;return g({value:e,tabValues:s})?e:null})();(0,l.A)(()=>{k&&o(k)},[k]);return{selectedValue:i,selectValue:(0,r.useCallback)(e=>{if(!g({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);o(e),u(e),b(e)},[u,b,s]),tabValues:s}}var k=n(2303);const m={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var x=n(4848);function v({className:e,block:a,selectedValue:n,selectValue:r,tabValues:s}){const o=[],{blockElementScrollPositionUntilNextRender:l}=(0,i.a_)(),c=e=>{const a=e.currentTarget,t=o.indexOf(a),i=s[t].value;i!==n&&(l(a),r(i))},u=e=>{let a=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const n=o.indexOf(e.currentTarget)+1;a=o[n]??o[0];break}case"ArrowLeft":{const n=o.indexOf(e.currentTarget)-1;a=o[n]??o[o.length-1];break}}a?.focus()};return(0,x.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,t.A)("tabs",{"tabs--block":a},e),children:s.map(({value:e,label:a,attributes:r})=>(0,x.jsx)("li",{role:"tab",tabIndex:n===e?0:-1,"aria-selected":n===e,ref:e=>{o.push(e)},onKeyDown:u,onClick:c,...r,className:(0,t.A)("tabs__item",m.tabItem,r?.className,{"tabs__item--active":n===e}),children:a??e},e))})}function y({lazy:e,children:a,selectedValue:n}){const s=(Array.isArray(a)?a:[a]).filter(Boolean);if(e){const e=s.find(e=>e.props.value===n);return e?(0,r.cloneElement)(e,{className:(0,t.A)("margin-top--md",e.props.className)}):null}return(0,x.jsx)("div",{className:"margin-top--md",children:s.map((e,a)=>(0,r.cloneElement)(e,{key:a,hidden:e.props.value!==n}))})}function j(e){const a=b(e);return(0,x.jsxs)("div",{className:(0,t.A)(s.G.tabs.container,"tabs-container",m.tabList),children:[(0,x.jsx)(v,{...a,...e}),(0,x.jsx)(y,{...a,...e})]})}function S(e){const a=(0,k.A)();return(0,x.jsx)(j,{...e,children:d(e.children)},String(a))}},5756:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>u,contentTitle:()=>c,default:()=>h,frontMatter:()=>l,metadata:()=>r,toc:()=>p});const r=JSON.parse('{"id":"libraries/installation/spark","title":"Spark configuration","description":"Instructions for configuring Apache Spark to use the Pathling library.","source":"@site/docs/libraries/installation/spark.md","sourceDirName":"libraries/installation","slug":"/libraries/installation/spark","permalink":"/docs/libraries/installation/spark","draft":false,"unlisted":false,"editUrl":"https://github.com/aehrc/pathling/tree/main/site/docs/libraries/installation/spark.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"description":"Instructions for configuring Apache Spark to use the Pathling library."},"sidebar":"libraries","previous":{"title":"Databricks installation","permalink":"/docs/libraries/installation/databricks"},"next":{"title":"Pre-release versions","permalink":"/docs/libraries/installation/prerelease"}}');var t=n(4848),s=n(8453),i=n(1470),o=n(9365);const l={sidebar_position:4,description:"Instructions for configuring Apache Spark to use the Pathling library."},c="Spark configuration",u={},p=[{value:"Session configuration",id:"session-configuration",level:2},{value:"Cluster configuration",id:"cluster-configuration",level:2}];function d(e){const a={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(a.header,{children:(0,t.jsx)(a.h1,{id:"spark-configuration",children:"Spark configuration"})}),"\n",(0,t.jsx)(a.h2,{id:"session-configuration",children:"Session configuration"}),"\n",(0,t.jsxs)(a.p,{children:["When you create a ",(0,t.jsx)(a.code,{children:"PathlingContext"})," within your Spark application, it will\ndetect the presence of an existing ",(0,t.jsx)(a.code,{children:"SparkSession"})," and use it. If there is no\nexisting session, it will create one for you with some sensible default\nconfiguration. You can override this default configuration by passing\na ",(0,t.jsx)(a.code,{children:"SparkSession"})," object to the ",(0,t.jsx)(a.code,{children:"PathlingContext"})," constructor."]}),"\n",(0,t.jsx)(a.p,{children:"This can be useful if you want to set other Spark configuration, for example to\nincrease the available memory."}),"\n",(0,t.jsxs)(a.p,{children:["The session that you provide must have the Pathling library API on the\nclasspath. You can also optionally enable ",(0,t.jsx)(a.a,{href:"https://delta.io/",children:"Delta Lake"}),"\nsupport. Here is an example of how to programmatically configure a session that\nhas Delta enabled:"]}),"\n","\n",(0,t.jsxs)(i.A,{children:[(0,t.jsx)(o.A,{value:"python",label:"Python",children:(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:'from pathling import PathlingContext\nfrom pyspark.sql import SparkSession\n\nspark = (\n    SparkSession.builder.config(\n        "spark.jars.packages",\n        "au.csiro.pathling:library-runtime:9.0.0," +\n        "io.delta:delta-spark_2.13:4.0.0"\n    )\n    .config(\n        "spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension"\n    )\n    .config(\n        "spark.sql.catalog.spark_catalog",\n        "org.apache.spark.sql.delta.catalog.DeltaCatalog",\n    ).getOrCreate()\n)\n\npc = PathlingContext.create(spark)\n'})})}),(0,t.jsx)(o.A,{value:"r",label:"R",children:(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-r",children:'library(sparklyr)\nlibrary(pathling)\n\nsc <- spark_connect(master = "local",\n                    packages = c(paste0("au.csiro.pathling:library-runtime:", pathling_version()),\n                                 "io.delta:delta-spark_2.13:4.0.0"),\n                    config = list("sparklyr.shell.conf" = c(\n                            "spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension",\n                            "spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog"\n                    )), version = "3.5.6")\n\npc <- pathling_connect(sc)\n'})})}),(0,t.jsx)(o.A,{value:"scala",label:"Scala",children:(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-scala",children:'import au.csiro.pathling.library.PathlingContext\n\nval spark = SparkSession.builder\n        .config("spark.jars.packages", "au.csiro.pathling:library-runtime:9.0.0," +\n                "io.delta:delta-spark_2.13:4.0.0")\n        .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension")\n        .config("spark.sql.catalog.spark_catalog",\n            "org.apache.spark.sql.delta.catalog.DeltaCatalog")\n        .getOrCreate()\n\nval pc = PathlingContext.create(spark)\n'})})}),(0,t.jsx)(o.A,{value:"java",label:"Java",children:(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-java",children:'import au.csiro.pathling.library.PathlingContext;\nimport org.apache.spark.sql.SparkSession;\n\nclass MyApp {\n\n    public static void main(String[] args) {\n        SparkSession spark = SparkSession.builder()\n                .config("spark.jars.packages",\n                        "au.csiro.pathling:library-runtime:9.0.0," +\n                                "io.delta:delta-spark_2.13:4.0.0")\n                .config("spark.sql.extensions",\n                        "io.delta.sql.DeltaSparkSessionExtension")\n                .config("spark.sql.catalog.spark_catalog",\n                        "org.apache.spark.sql.delta.catalog.DeltaCatalog")\n                .getOrCreate();\n        PathlingContext pc = PathlingContext.create(spark);\n    }\n}\n'})})})]}),"\n",(0,t.jsx)(a.h2,{id:"cluster-configuration",children:"Cluster configuration"}),"\n",(0,t.jsxs)(a.p,{children:["If you are running your own Spark cluster, or using a Docker image (such\nas ",(0,t.jsx)(a.a,{href:"https://hub.docker.com/r/jupyter/all-spark-notebook",children:"jupyter/all-spark-notebook"}),"),\nyou will need to configure Pathling as a Spark package."]}),"\n",(0,t.jsxs)(a.p,{children:["You can do this by adding the following to your ",(0,t.jsx)(a.code,{children:"spark-defaults.conf"})," file:"]}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"spark.jars.packages au.csiro.pathling:library-runtime:[some version]\n"})}),"\n",(0,t.jsxs)(a.p,{children:["See the ",(0,t.jsx)(a.a,{href:"https://spark.apache.org/docs/latest/configuration.html",children:"Configuration"}),"\npage of the Spark documentation for more information about ",(0,t.jsx)(a.code,{children:"spark.jars.packages"}),"\nand other related configuration options."]}),"\n",(0,t.jsxs)(a.p,{children:["To create a Pathling notebook Docker image, your ",(0,t.jsx)(a.code,{children:"Dockerfile"})," might look like\nthis:"]}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-dockerfile",children:'FROM jupyter/all-spark-notebook\n\nUSER root\nRUN echo "spark.jars.packages au.csiro.pathling:library-runtime:[some version]" >> /usr/local/spark/conf/spark-defaults.conf\n\nUSER ${NB_UID}\n\nRUN pip install --quiet --no-cache-dir pathling && \\\n    fix-permissions "${CONDA_DIR}" && \\\n    fix-permissions "/home/${NB_USER}"\n'})})]})}function h(e={}){const{wrapper:a}={...(0,s.R)(),...e.components};return a?(0,t.jsx)(a,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,a,n)=>{n.d(a,{R:()=>i,x:()=>o});var r=n(6540);const t={},s=r.createContext(t);function i(e){const a=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function o(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),r.createElement(s.Provider,{value:a},e.children)}},9365:(e,a,n)=>{n.d(a,{A:()=>i});n(6540);var r=n(4164);const t={tabItem:"tabItem_Ymn6"};var s=n(4848);function i({children:e,hidden:a,className:n}){return(0,s.jsx)("div",{role:"tabpanel",className:(0,r.A)(t.tabItem,n),hidden:a,children:e})}}}]);