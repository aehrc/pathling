"use strict";(globalThis.webpackChunkpathling_site=globalThis.webpackChunkpathling_site||[]).push([[2016],{5557:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"server/deployment/synchronization","title":"Synchronization","description":"Keep Pathling in sync with a source FHIR server using scheduled jobs and the $import-pnp operation.","source":"@site/docs/server/deployment/synchronization.md","sourceDirName":"server/deployment","slug":"/server/deployment/synchronization","permalink":"/docs/server/deployment/synchronization","draft":false,"unlisted":false,"editUrl":"https://github.com/aehrc/pathling/tree/main/site/docs/server/deployment/synchronization.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"sidebar_label":"Synchronization","description":"Keep Pathling in sync with a source FHIR server using scheduled jobs and the $import-pnp operation."},"sidebar":"server","previous":{"title":"Kubernetes","permalink":"/docs/server/deployment/kubernetes"}}');var t=r(4848),i=r(8453);const o={sidebar_position:3,sidebar_label:"Synchronization",description:"Keep Pathling in sync with a source FHIR server using scheduled jobs and the $import-pnp operation."},a="Synchronization",c={},l=[{value:"Configuration",id:"configuration",level:2},{value:"Sync script",id:"sync-script",level:2},{value:"Scheduling with cron",id:"scheduling-with-cron",level:2},{value:"Scheduling with Kubernetes CronJob",id:"scheduling-with-kubernetes-cronjob",level:2},{value:"Considerations",id:"considerations",level:2},{value:"Save mode",id:"save-mode",level:3},{value:"Sync frequency",id:"sync-frequency",level:3},{value:"Incremental sync",id:"incremental-sync",level:3},{value:"Error handling",id:"error-handling",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"synchronization",children:"Synchronization"})}),"\n",(0,t.jsxs)(n.p,{children:["Pathling can be kept in sync with a source FHIR server that supports\n",(0,t.jsx)(n.a,{href:"https://hl7.org/fhir/uv/bulkdata/",children:"FHIR Bulk Data Export"}),". This is useful when\nyou want to use Pathling's analytics capabilities on data that originates from\nanother system."]}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsxs)(n.a,{href:"/docs/server/operations/import-pnp",children:[(0,t.jsx)(n.code,{children:"$import-pnp"})," operation"]})," fetches data\ndirectly from a bulk export endpoint. By running this operation on a schedule,\nyou can keep Pathling synchronized with your source system."]}),"\n",(0,t.jsx)(n.mermaid,{value:'flowchart LR\n    subgraph Source System\n        S[FHIR Server]\n    end\n\n    subgraph Scheduler\n        C[Cron / CronJob]\n    end\n\n    subgraph Pathling\n        P[Pathling Server]\n    end\n\n    C --\x3e|"POST /$import-pnp"| P\n    P --\x3e|"GET /$export"| S\n    S --\x3e|NDJSON files| P'}),"\n",(0,t.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,t.jsxs)(n.p,{children:["Before setting up synchronization, configure Pathling with the authentication\ncredentials for the source server. See the\n",(0,t.jsx)(n.a,{href:"/docs/server/configuration#ping-and-pull",children:"ping and pull configuration"})," section."]}),"\n",(0,t.jsx)(n.p,{children:"Example configuration for a source server using SMART Backend Services\nauthentication:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'pathling:\n    import:\n        pnp:\n            clientId: pathling-client\n            tokenEndpoint: https://source-server.example.com/auth/token\n            privateKeyJwk: \'{"kty":"RSA","n":"...","e":"AQAB","d":"...","p":"...","q":"...","dp":"...","dq":"...","qi":"..."}\'\n            scope: system/*.read\n'})}),"\n",(0,t.jsx)(n.h2,{id:"sync-script",children:"Sync script"}),"\n",(0,t.jsxs)(n.p,{children:["The following script invokes the ",(0,t.jsx)(n.code,{children:"$import-pnp"})," operation and waits for\ncompletion. Save it as ",(0,t.jsx)(n.code,{children:"sync.sh"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\nset -euo pipefail\n\nPATHLING_URL="${PATHLING_URL:-http://localhost:8080/fhir}"\nSOURCE_EXPORT_URL="${SOURCE_EXPORT_URL:-https://source-server.example.com/fhir/\\$export}"\nSAVE_MODE="${SAVE_MODE:-merge}"\nTIMEOUT="${TIMEOUT:-7200}"\n# Optional: comma-separated list of resource types (e.g., "Patient,Observation")\nRESOURCE_TYPES="${RESOURCE_TYPES:-}"\n# Optional: ISO timestamp for incremental sync (e.g., "2025-01-01T00:00:00Z")\nSINCE="${SINCE:-}"\n\n# Build parameters array\nPARAMS="[{\\"name\\": \\"exportUrl\\", \\"valueUrl\\": \\"$SOURCE_EXPORT_URL\\"}"\nPARAMS="$PARAMS,{\\"name\\": \\"saveMode\\", \\"valueCode\\": \\"$SAVE_MODE\\"}"\n\n# Add resource type filters\nif [ -n "$RESOURCE_TYPES" ]; then\n  IFS=\',\' read -ra TYPES <<< "$RESOURCE_TYPES"\n  for TYPE in "${TYPES[@]}"; do\n    PARAMS="$PARAMS,{\\"name\\": \\"_type\\", \\"valueString\\": \\"$TYPE\\"}"\n  done\nfi\n\n# Add timestamp filter for incremental sync\nif [ -n "$SINCE" ]; then\n  PARAMS="$PARAMS,{\\"name\\": \\"_since\\", \\"valueInstant\\": \\"$SINCE\\"}"\nfi\n\nPARAMS="$PARAMS]"\nREQUEST_BODY="{\\"resourceType\\": \\"Parameters\\", \\"parameter\\": $PARAMS}"\n\n# Kick off the import\necho "Starting import from: $SOURCE_EXPORT_URL"\n[ -n "$RESOURCE_TYPES" ] && echo "Resource types: $RESOURCE_TYPES"\n[ -n "$SINCE" ] && echo "Since: $SINCE"\n\nSTATUS_URL=$(curl -s -D - -X POST "$PATHLING_URL/\\$import-pnp" \\\n  -H "Content-Type: application/fhir+json" \\\n  -H "Accept: application/fhir+json" \\\n  -H "Prefer: respond-async" \\\n  -d "$REQUEST_BODY" | grep -i "Content-Location" | cut -d\' \' -f2 | tr -d \'\\r\')\n\nif [ -z "$STATUS_URL" ]; then\n  echo "Failed to start import: no Content-Location header"\n  exit 1\nfi\n\necho "Polling status: $STATUS_URL"\n\n# Poll until complete\nSTART_TIME=$(date +%s)\nINTERVAL=5\n\nwhile true; do\n  ELAPSED=$(($(date +%s) - START_TIME))\n  if [ $ELAPSED -gt $TIMEOUT ]; then\n    echo "Timeout after ${TIMEOUT}s"\n    exit 1\n  fi\n\n  HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$STATUS_URL" \\\n    -H "Accept: application/fhir+json")\n\n  if [ "$HTTP_CODE" = "200" ]; then\n    echo "Import complete"\n    curl -s "$STATUS_URL" -H "Accept: application/fhir+json"\n    exit 0\n  elif [ "$HTTP_CODE" = "202" ]; then\n    echo "In progress... (${ELAPSED}s elapsed)"\n    sleep $INTERVAL\n    # Exponential backoff up to 60s\n    INTERVAL=$((INTERVAL < 60 ? INTERVAL * 3 / 2 : 60))\n  else\n    echo "Error: HTTP $HTTP_CODE"\n    exit 1\n  fi\ndone\n'})}),"\n",(0,t.jsx)(n.p,{children:"Make the script executable:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"chmod +x sync.sh\n"})}),"\n",(0,t.jsx)(n.p,{children:"Test it manually:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"PATHLING_URL=http://localhost:8080/fhir \\\nSOURCE_EXPORT_URL=https://source-server.example.com/fhir/\\$export \\\n./sync.sh\n"})}),"\n",(0,t.jsx)(n.h2,{id:"scheduling-with-cron",children:"Scheduling with cron"}),"\n",(0,t.jsx)(n.p,{children:"On Linux or macOS, use cron to run the sync script on a schedule."}),"\n",(0,t.jsx)(n.p,{children:"Edit your crontab:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"crontab -e\n"})}),"\n",(0,t.jsx)(n.p,{children:"Add an entry to run the sync daily at 2 AM:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-cron",children:"0 2 * * * PATHLING_URL=http://localhost:8080/fhir SOURCE_EXPORT_URL=https://source-server.example.com/fhir/\\$export /path/to/sync.sh >> /var/log/pathling-sync.log 2>&1\n"})}),"\n",(0,t.jsx)(n.h2,{id:"scheduling-with-kubernetes-cronjob",children:"Scheduling with Kubernetes CronJob"}),"\n",(0,t.jsxs)(n.p,{children:["For Kubernetes deployments, use a\n",(0,t.jsx)(n.a,{href:"https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/",children:"CronJob"}),"\nto run the sync on a schedule."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'apiVersion: batch/v1\nkind: CronJob\nmetadata:\n    name: pathling-sync\nspec:\n    schedule: "0 2 * * *" # Daily at 2 AM\n    concurrencyPolicy: Forbid\n    jobTemplate:\n        spec:\n            template:\n                spec:\n                    containers:\n                        - name: sync\n                          image: curlimages/curl:latest\n                          env:\n                              - name: PATHLING_URL\n                                value: "http://pathling:8080/fhir"\n                              - name: SOURCE_EXPORT_URL\n                                value: "https://source-server.example.com/fhir/$export"\n                              - name: SAVE_MODE\n                                value: "merge"\n                              # Optional: comma-separated resource types\n                              - name: RESOURCE_TYPES\n                                value: ""\n                              # Optional: ISO timestamp for incremental sync\n                              - name: SINCE\n                                value: ""\n                          command:\n                              - /bin/sh\n                              - -c\n                              - |\n                                  # Build parameters\n                                  PARAMS="[{\\"name\\": \\"exportUrl\\", \\"valueUrl\\": \\"$SOURCE_EXPORT_URL\\"}"\n                                  PARAMS="$PARAMS,{\\"name\\": \\"saveMode\\", \\"valueCode\\": \\"$SAVE_MODE\\"}"\n\n                                  # Add resource type filters\n                                  if [ -n "$RESOURCE_TYPES" ]; then\n                                    for TYPE in $(echo "$RESOURCE_TYPES" | tr \',\' \' \'); do\n                                      PARAMS="$PARAMS,{\\"name\\": \\"_type\\", \\"valueString\\": \\"$TYPE\\"}"\n                                    done\n                                  fi\n\n                                  # Add timestamp filter\n                                  if [ -n "$SINCE" ]; then\n                                    PARAMS="$PARAMS,{\\"name\\": \\"_since\\", \\"valueInstant\\": \\"$SINCE\\"}"\n                                  fi\n\n                                  PARAMS="$PARAMS]"\n\n                                  # Kick off import\n                                  STATUS_URL=$(curl -s -D - -X POST "$PATHLING_URL/\\$import-pnp" \\\n                                    -H "Content-Type: application/fhir+json" \\\n                                    -H "Accept: application/fhir+json" \\\n                                    -H "Prefer: respond-async" \\\n                                    -d "{\\"resourceType\\": \\"Parameters\\", \\"parameter\\": $PARAMS}" \\\n                                    | grep -i "Content-Location" | cut -d\' \' -f2 | tr -d \'\\r\')\n\n                                  echo "Polling: $STATUS_URL"\n\n                                  # Poll until complete (timeout 2 hours)\n                                  for i in $(seq 1 240); do\n                                    CODE=$(curl -s -o /dev/null -w "%{http_code}" "$STATUS_URL")\n                                    if [ "$CODE" = "200" ]; then\n                                      echo "Complete"\n                                      exit 0\n                                    fi\n                                    sleep 30\n                                  done\n                                  echo "Timeout"\n                                  exit 1\n                    restartPolicy: OnFailure\n'})}),"\n",(0,t.jsx)(n.h2,{id:"considerations",children:"Considerations"}),"\n",(0,t.jsx)(n.h3,{id:"save-mode",children:"Save mode"}),"\n",(0,t.jsx)(n.p,{children:"Choose the appropriate save mode for your use case:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"merge"})})," \u2014 Best for incremental sync. Updates existing resources and adds\nnew ones. Use with ",(0,t.jsx)(n.code,{children:"_since"})," parameter for efficient incremental updates."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"overwrite"})})," \u2014 Best for full replacement. Deletes all existing data of each\ntype before importing. Ensures exact mirror of source system."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"sync-frequency",children:"Sync frequency"}),"\n",(0,t.jsx)(n.p,{children:"Consider these factors when choosing sync frequency:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Data freshness requirements"})," \u2014 How current does the data need to be?"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Source system load"})," \u2014 Bulk exports can be resource-intensive"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Data volume"})," \u2014 Larger datasets take longer to export and import"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Network bandwidth"})," \u2014 Consider the time to transfer data"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"For most analytics use cases, daily or hourly sync is sufficient."}),"\n",(0,t.jsx)(n.h3,{id:"incremental-sync",children:"Incremental sync"}),"\n",(0,t.jsxs)(n.p,{children:["For large datasets, use incremental sync to reduce load. The ",(0,t.jsx)(n.code,{children:"$import-pnp"}),"\noperation supports passing bulk export parameters directly, including ",(0,t.jsx)(n.code,{children:"_since"}),"\nfor timestamp filtering and ",(0,t.jsx)(n.code,{children:"_type"})," for resource type filtering."]}),"\n",(0,t.jsxs)(n.p,{children:["Set the ",(0,t.jsx)(n.code,{children:"SINCE"})," environment variable to export only resources modified after a\nspecific timestamp:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'SINCE="2025-01-01T00:00:00Z" ./sync.sh\n'})}),"\n",(0,t.jsxs)(n.p,{children:["You can also filter by resource type using the ",(0,t.jsx)(n.code,{children:"RESOURCE_TYPES"})," variable:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'RESOURCE_TYPES="Patient,Observation,Condition" SINCE="2025-01-01T00:00:00Z" ./sync.sh\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Track the last successful sync time and use it for the next ",(0,t.jsx)(n.code,{children:"_since"})," parameter.\nThe ",(0,t.jsx)(n.code,{children:"transactionTime"})," in the import response provides a good value to use for\nsubsequent syncs."]}),"\n",(0,t.jsx)(n.h3,{id:"error-handling",children:"Error handling"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Retry logic"})," \u2014 The CronJob's ",(0,t.jsx)(n.code,{children:"restartPolicy: OnFailure"})," provides automatic\nretries"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Monitoring"})," \u2014 Set up alerts on job failures using your monitoring system"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Logging"})," \u2014 Ensure logs are captured for troubleshooting"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>a});var s=r(6540);const t={},i=s.createContext(t);function o(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);