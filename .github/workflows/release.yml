# This workflow builds a release version of Pathling and deploys it to Maven Central and PyPI.

name: Release

# This workflow is only run when a release is published.
on:
  release:
    types: [published]
  workflow_dispatch:

env:
  # The add-exports and add-opens flags are required for Java 17
  MAVEN_OPTS: --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED

permissions:
  id-token: write
  contents: write # Required to upload release assets

jobs:
  release-maven:
    name: Release to Maven Central
    environment: maven-central
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: recursive

      - name: Set up JDK
        uses: actions/setup-java@v4
        with:
          java-version: 17
          distribution: "zulu"

      - name: Set up Python 3.8
        uses: actions/setup-python@v4
        id: python-install
        with:
          python-version: 3.8

      - name: Set up R
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: "4.1.3"
          use-public-rspm: true

      - name: Set up Pandoc
        uses: r-lib/actions/setup-pandoc@v2

      - name: Cache local Maven repository
        uses: actions/cache@v4
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
          restore-keys: |-
            ${{ runner.os }}-maven-

      - name: Cache Python packages
        uses: actions/cache@v4
        with:
          path: /home/runner/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('lib/python/requirements/dev.txt', 'lib/python/requirements/package.txt') }}

      - name: Cache R packages
        uses: actions/cache@v4
        with:
          path: ${{ runner.temp }}/Library
          key: r-packages-${{ runner.os }}-${{ hashFiles('lib/R/DESCRIPTION.src') }}
          restore-keys: r-packages-${{ runner.os }}-

      - name: Cache SonarQube packages
        uses: actions/cache@v4
        with:
          path: ~/.sonar/cache
          key: ${{ runner.os }}-sonar
          restore-keys: ${{ runner.os }}-sonar

      - name: Install TinyTeX and libcurl
        # These are required for building the R package documentation.
        run: |
          wget -qO- "https://yihui.org/tinytex/install-bin-unix.sh" | sh
          echo "$HOME/bin" >> $GITHUB_PATH
          sudo apt-get install -y libcurl4-openssl-dev

      - name: Install GPG key
        run: |
          cat <(echo -e "${{ secrets.GPG_KEY }}") | gpg --batch --import
          gpg --list-secret-keys --keyid-format LONG

      - name: Configure Maven settings
        uses: s4u/maven-settings-action@v3.1.0
        with:
          servers: |
            [{
              "id": "central",
              "username": "${{ secrets.OSSRH_USERNAME }}",
              "password": "${{ secrets.OSSRH_PASSWORD }}"
            }]

      # Release won't be possible if there are outstanding vulnerabilities of medium severity or
      # higher as reported by Trivy.
      - name: Run security scan
        uses: aquasecurity/trivy-action@0.32.0
        with:
          scan-type: repo
          severity: "MEDIUM,HIGH,CRITICAL"
          scan-ref: .
          format: sarif
          output: trivy-results.sarif
          skip-files: examples/**/*,**/target/**/*,sql-on-fhir/sof-js/package-lock.json,licenses/**/*,site/package-lock.json
          # Upon release, the databases will be updated and scanned to make sure nothing has crept
          # in since the last daily update.
          cache: false

      - name: Run deploy goal
        env:
          PYSPARK_PYTHON: ${{ steps.python-install.outputs.python-path }}
          PYSPARK_DRIVER_PYTHON: ${{ steps.python-install.outputs.python-path }}
          R_KEEP_PKG_SOURCE: yes
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          MAVEN_GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}
        run: |
          mvn --batch-mode deploy \
          org.sonarsource.scanner.maven:sonar-maven-plugin:sonar \
          -Dsonar.projectKey=aehrc_pathling -Dsonar.organization=aehrc \
          -Dsonar.host.url=https://sonarcloud.io \
          -Dsonar.sarifReportPaths=trivy-results.sarif \
          -pl '!benchmark' -Pdocs,mavenRelease
        timeout-minutes: 60

      - name: Save test reports
        uses: actions/upload-artifact@v4
        with:
          name: surefire-reports
          path: "**/surefire-reports/"

      - name: Save coverage reports
        uses: actions/upload-artifact@v4
        with:
          name: coverage-reports
          path: |
            **/jacoco.xml
            **/target/site/jacoco
            **/target/site/jacoco-aggregate
            lib/python/**/coverage.xml

      - name: Save built JARs
        uses: actions/upload-artifact@v4
        with:
          name: jars
          path: |
            utilities/target/utilities-*.jar
            encoders/target/encoders-*.jar
            terminology/target/terminology-*.jar
            fhirpath/target/fhirpath-*.jar
            library-api/target/library-api-*.jar
            library-runtime/target/library-runtime-*.jar
            lib/python/target/python-*.jar
            lib/R/target/r-*.jar
          if-no-files-found: "error"

      - name: Save Python wheel
        uses: actions/upload-artifact@v4
        with:
          name: python-wheel
          path: lib/python/target/py-dist/pathling-*.whl

      - name: Save R package
        uses: actions/upload-artifact@v4
        with:
          name: r-package
          path: lib/R/target/pathling_*.tar.gz

      - name: Save site
        uses: actions/upload-artifact@v4
        with:
          name: site
          path: site/target/site/

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::865780493209:role/PathlingBenchmarkUpload
          aws-region: ap-southeast-2

      - name: Upload SQL on FHIR test report to S3
        run: aws s3 cp fhirpath/target/fhir-view-compliance-test.json s3://pathling-benchmark/test-reports/${{ github.ref }}/sof-test-results.json

      - name: Upload release assets
        run: |
          gh release upload ${{ github.ref_name }} \
            --clobber \
            library-runtime/target/library-runtime-*.jar \
            lib/python/target/py-dist/pathling-*.whl \
            lib/R/target/pathling_*.tar.gz
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  release-pypi:
    name: Release to PyPI
    environment: pypi
    runs-on: ubuntu-latest
    needs: release-maven
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          # This is required so that git-commit-id-plugin can find the latest tag.
          fetch-depth: 0
          submodules: recursive

      - name: Set up JDK
        uses: actions/setup-java@v4
        with:
          java-version: 17
          distribution: "zulu"

      - name: Set up Python 3.8
        uses: actions/setup-python@v4
        id: python-install
        with:
          python-version: 3.8

      - name: Set up R
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: "4.1.3"
          use-public-rspm: true

      - name: Set up Pandoc
        uses: r-lib/actions/setup-pandoc@v2

      - name: Cache local Maven repository
        uses: actions/cache@v4
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-

      - name: Cache Python packages
        uses: actions/cache@v4
        with:
          path: /home/runner/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('lib/python/requirements/dev.txt', 'lib/python/requirements/package.txt') }}

      - name: Cache R packages
        uses: actions/cache@v4
        with:
          path: ${{ runner.temp }}/Library
          key: r-packages-${{ runner.os }}-${{ hashFiles('lib/R/DESCRIPTION.src') }}
          restore-keys: r-packages-${{ runner.os }}-

      - name: Install TinyTeX and libcurl
        # These are required for building the R package documentation.
        run: |
          wget -qO- "https://yihui.org/tinytex/install-bin-unix.sh" | sh
          echo "$HOME/bin" >> $GITHUB_PATH
          sudo apt-get install -y libcurl4-openssl-dev

      - name: Run deploy goal
        env:
          PYSPARK_PYTHON: ${{ steps.python-install.outputs.python-path }}
          PYSPARK_DRIVER_PYTHON: ${{ steps.python-install.outputs.python-path }}
          TWINE_USERNAME: ${{ secrets.TWINE_USERNAME }}
          TWINE_PASSWORD: ${{ secrets.TWINE_PASSWORD }}
          R_KEEP_PKG_SOURCE: yes
        run: |
          mvn --batch-mode deploy \
          -pl lib/python -am \
          -DskipTests -PpythonRelease
        timeout-minutes: 30

  upload-to-dap:
    name: Upload source code to CSIRO DAP
    environment: csiro-dap
    runs-on: ubuntu-latest
    needs: [release-maven, release-pypi]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download source code and upload to CSIRO DAP
        shell: python
        run: |
          import json
          import os
          import sys
          import time
          import urllib.parse
          import urllib.request
          import base64

          def create_auth_header(username, password):
              """Create Basic authentication header"""
              credentials = f"{username}:{password}"
              encoded = base64.b64encode(credentials.encode()).decode()
              return f"Basic {encoded}"

          def make_request(url, method="GET", data=None, headers=None, auth_header=None):
              """Make HTTP request with optional authentication"""
              if headers is None:
                  headers = {}
              
              if auth_header:
                  headers["Authorization"] = auth_header
              
              if data is not None:
                  if isinstance(data, dict):
                      data = json.dumps(data).encode()
                      headers["Content-Type"] = "application/json"
                  elif isinstance(data, str):
                      data = data.encode()
                      
              req = urllib.request.Request(url, data=data, headers=headers, method=method)
              
              try:
                  with urllib.request.urlopen(req) as response:
                      return response.read().decode(), response.getcode()
              except urllib.error.HTTPError as e:
                  return e.read().decode(), e.code

          def upload_file_with_presigned_url(file_path, presigned_url):
              """Upload file using presigned URL with PUT request"""
              try:
                  with open(file_path, 'rb') as f:
                      file_data = f.read()
                  
                  req = urllib.request.Request(presigned_url, data=file_data, method='PUT')
                  req.add_header('Content-Type', 'application/zip')
                  
                  with urllib.request.urlopen(req) as response:
                      return response.read().decode(), response.getcode()
              except urllib.error.HTTPError as e:
                  return e.read().decode(), e.code

          # Configuration
          GITHUB_REPOSITORY = "${{ github.repository }}"
          GITHUB_REF_NAME = "${{ github.ref_name }}"
          GITHUB_TOKEN = "${{ secrets.GITHUB_TOKEN }}"
          DAP_USERNAME = "${{ secrets.DAP_USERNAME }}"
          DAP_PASSWORD = "${{ secrets.DAP_PASSWORD }}"
          DAP_BASE_URL = "https://data.csiro.au"
          COLLECTION_PID = "csiro:49524"

          # Step 1: Download source code ZIP from release
          print("=== CSIRO DAP Upload (Python Method) ===")
          print(f"Repository: {GITHUB_REPOSITORY}")
          print(f"Release: {GITHUB_REF_NAME}")
          print()

          # Extract version from tag (remove 'v' prefix if present)
          version = GITHUB_REF_NAME
          if version.startswith('v'):
              version = version[1:]

          zip_filename = f"pathling-{version}.zip"

          print(f"Step 1: Downloading source code archive...")
          print(f"Target file: {zip_filename}")

          # Download the automatic source code archive from GitHub
          github_api_url = f"https://api.github.com/repos/{GITHUB_REPOSITORY}/zipball/{GITHUB_REF_NAME}"

          req = urllib.request.Request(github_api_url)
          req.add_header('Authorization', f'token {GITHUB_TOKEN}')
          req.add_header('Accept', 'application/vnd.github.v3+json')

          try:
              with urllib.request.urlopen(req) as response:
                  if response.getcode() != 200:
                      print(f"Error: Failed to download source archive (HTTP {response.getcode()})")
                      sys.exit(1)
                  
                  with open(zip_filename, 'wb') as f:
                      f.write(response.read())
          except Exception as e:
              print(f"Error: Failed to download source code archive: {e}")
              sys.exit(1)

          # Verify that the ZIP file was downloaded
          if not os.path.exists(zip_filename):
              print(f"Error: Failed to download source code archive for {GITHUB_REF_NAME}")
              sys.exit(1)

          file_size = os.path.getsize(zip_filename)
          print(f"Downloaded source code archive: {zip_filename}")
          print(f"File size: {file_size:,} bytes ({file_size / (1024*1024):.1f} MB)")
          print()

          # Step 2: Upload to CSIRO DAP
          auth_header = create_auth_header(DAP_USERNAME, DAP_PASSWORD)

          # Get collection information
          print(f"Step 2: Getting collection information for {COLLECTION_PID}...")
          response_text, status_code = make_request(
              f"{DAP_BASE_URL}/dap/api/v2/my-collections",
              auth_header=auth_header
          )

          if status_code != 200:
              print(f"Error: Failed to get collections (HTTP {status_code})")
              print(response_text[:500])
              sys.exit(1)

          collections = json.loads(response_text)

          # Find the collection with the specified PID
          collection_data = None
          for collection in collections:
              if collection.get("dataCollectionPid") == COLLECTION_PID:
                  collection_data = collection
                  break

          if not collection_data:
              print(f"Error: Collection {COLLECTION_PID} not found or not accessible")
              sys.exit(1)

          collection_id = collection_data["dataCollectionId"]
          collection_status = collection_data["status"]

          print(f"Found collection ID: {collection_id} (Status: {collection_status})")
          print()

          # Create a new version of the collection (or use existing draft)
          if collection_status == "Draft":
              print("Step 3: Using existing draft version...")
              new_collection_id = collection_id
          else:
              print("Step 3: Creating new version of collection...")
              response_text, status_code = make_request(
                  f"{DAP_BASE_URL}/dap/api/v2/collections/{collection_id}/update",
                  method="POST",
                  auth_header=auth_header
              )
              
              if status_code != 201:
                  print(f"Error: Failed to create new version (HTTP {status_code})")
                  print(response_text[:500])
                  sys.exit(1)
              
              update_response = json.loads(response_text)
              new_collection_id = update_response["dataCollectionId"]
              
              if not new_collection_id:
                  print("Error: Failed to get new collection ID")
                  print(response_text[:500])
                  sys.exit(1)
              
              print(f"Created new collection version with ID: {new_collection_id}")
          print()

          # Unlock files for modification
          print("Step 4: Unlocking files for modification...")
          response_text, status_code = make_request(
              f"{DAP_BASE_URL}/dap/api/v2/collections/{new_collection_id}/files/unlock",
              method="POST",
              auth_header=auth_header
          )

          if status_code not in [200, 204]:
              print(f"Warning: Unlock request returned HTTP {status_code}")
              print(response_text[:200])

          # Wait for files to be unlocked
          print("Step 5: Waiting for files to be unlocked...")
          max_attempts = 24  # 2 minutes with 5-second intervals
          attempt = 0

          while attempt < max_attempts:
              time.sleep(5)
              response_text, status_code = make_request(
                  f"{DAP_BASE_URL}/dap/api/v2/collections/{new_collection_id}/files/fileState",
                  auth_header=auth_header
              )
              
              print(f"File state response: {response_text}")
              
              try:
                  file_state_data = json.loads(response_text)
                  file_state = file_state_data.get("value", response_text.strip())
              except json.JSONDecodeError:
                  file_state = response_text.strip()
              
              if file_state == "unlocked":
                  break
              elif file_state == "error":
                  print("Error: Failed to unlock files")
                  sys.exit(1)
              
              attempt += 1

          if attempt >= max_attempts:
              print("Error: Timeout waiting for files to unlock")
              sys.exit(1)

          print("Files unlocked successfully!")
          print()

          # Upload file using presigned URL method
          print("Step 6: Uploading file using presigned URL method...")

          # Get presigned URL (URL encode the path)
          file_path = f"/{zip_filename}"
          encoded_path = urllib.parse.quote(file_path)
          print(f"Getting presigned URL for path: {file_path}")

          response_text, status_code = make_request(
              f"{DAP_BASE_URL}/dap/api/v2/collections/{new_collection_id}/files/s3uploadurl?path={encoded_path}",
              auth_header=auth_header
          )

          # Check if we got a valid URL (not HTML error)
          if status_code != 200 or response_text.startswith("<!doctype") or response_text.startswith("<html"):
              print("Error: Failed to get presigned URL. Response:")
              print(response_text[:500])
              sys.exit(1)

          presigned_url = response_text.strip()
          print(f"Presigned URL obtained (length: {len(presigned_url)} characters)")
          print(f"URL preview: {presigned_url[:100]}...")
          print()

          # Upload file using the presigned URL
          print("Uploading file using presigned URL...")
          upload_response, upload_status = upload_file_with_presigned_url(zip_filename, presigned_url)

          print(f"HTTP Response Code: {upload_status}")
          if upload_status == 200:
              print("✓ File uploaded successfully!")
          else:
              print("✗ Upload failed. Response:")
              print(upload_response[:500])
              sys.exit(1)
          print()

          # Validate the collection
          print("Step 7: Validating collection...")
          response_text, status_code = make_request(
              f"{DAP_BASE_URL}/dap/api/v2/collections/{new_collection_id}/validate",
              auth_header=auth_header
          )

          print(f"Validation response: {response_text}")

          try:
              validation_data = json.loads(response_text)
              validation_errors = validation_data.get("errors", [])
              if validation_errors and validation_errors != []:
                  print(f"Warning: Validation errors found: {validation_errors}")
              else:
                  print("✓ Collection validation passed!")
          except json.JSONDecodeError:
              print(f"Note: Could not parse validation response as JSON: {response_text}")
          print()

          # Submit collection for publication
          print("Step 8: Submitting collection for publication...")
          submit_payload = {
              "approver": None,
              "businessUnit": None,
              "notesToApprover": None,
              "supportingFilesForApprover": []
          }

          response_text, status_code = make_request(
              f"{DAP_BASE_URL}/dap/api/v2/collections/{new_collection_id}/submit",
              method="POST",
              data=submit_payload,
              auth_header=auth_header
          )

          print(f"Submit response (HTTP {status_code}): {response_text}")
          if status_code in [200, 201, 204]:
              print("✓ Collection submitted for publication!")
          else:
              print(f"Warning: Submit returned HTTP {status_code}")
          print()

          print("=== Upload Complete ===")
          print(f"New collection ID: {new_collection_id}")
          print(f"Collection URL: {DAP_BASE_URL}/dap/collections/{new_collection_id}")
          print()
          print("The collection should now be visible in the DAP environment.")
        timeout-minutes: 20
